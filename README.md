ğŸ· Red Wine Quality Analysis (UCI ML Repository)

ğŸ“Œ Project Overview

This project analyzes the Red Wine Quality dataset from the UCI Machine Learning Repository. The goal is to explore the chemical properties of red wine, identify the features most correlated with wine quality, and build predictive models.

The project covers:
	â€¢	Exploratory Data Analysis (EDA) to uncover patterns
	â€¢	Feature Engineering for improved modeling
	â€¢	Regression models to predict quality scores
	â€¢	Model Interpretability for real-world insights


ğŸ¯ Objectives
	â€¢	Understand how physicochemical properties influence wine quality.
	â€¢	Build regression models to predict wine quality (0â€“10).
	â€¢	Compare model performance (Linear Regression, Random Forest, XGBoost).
	â€¢	Interpret model results with explainability tools (SHAP).


ğŸ“‚ Dataset Details
	â€¢	Source: UCI Machine Learning Repository
	â€¢	Authors: Paulo Cortez et al., University of Minho, Portugal
	â€¢	Observations: 1,599 red wines
	â€¢	Features: 11 physicochemical properties (e.g., acidity, sugar, sulphates, alcohol)
	â€¢	Target Variable: quality (wine quality score, 0â€“10, by wine experts)


ğŸ§­ Workflow

1. Data Preprocessing
	â€¢	Check nulls & data types
	â€¢	Outlier detection & handling
	â€¢	Scaling numeric features

2. EDA
	â€¢	Distribution of quality scores
	â€¢	Correlation heatmap between features & target
	â€¢	Pairplots (e.g., alcohol vs. quality)
	â€¢	Boxplots of features across quality categories

3. Feature Engineering
	â€¢	Convert quality scores into categories (Low, Medium, High)
	â€¢	Feature interactions (alcohol Ã— acidity)
	â€¢	Standardization & normalization

4. Modeling
	â€¢	Train/test split
	â€¢	Linear Regression as baseline
	â€¢	Random Forest & XGBoost for non-linear patterns
	â€¢	Evaluation Metrics: RMSE, MAE, RÂ²

5. Model Interpretation
	â€¢	Feature importances (tree-based models)
	â€¢	SHAP values â†’ interpret what drives quality



ğŸ“Š Key Insights
	â€¢	Alcohol is the strongest predictor of wine quality.
	â€¢	Wines with low volatile acidity and higher sulphates tend to score higher.
	â€¢	Ensemble methods (Random Forest, XGBoost) capture non-linear patterns better than linear models.



âš™ï¸ Tools & Libraries
	â€¢	Python 3.12
	â€¢	pandas, numpy
	â€¢	matplotlib, seaborn
	â€¢	scikit-learn
	â€¢	XGBoost
	â€¢	SHAP



ğŸ“ˆ Results (Example)
	â€¢	Linear Regression RÂ²: ~0.20
	â€¢	Random Forest RÂ²: ~0.58
	â€¢	XGBoost RÂ²: ~0.64
	â€¢	Top predictors: alcohol, volatile acidity, sulphates
